# Script para cargar los metadatos de maps.

maps_metadata = pd.DataFrame()
lista_metadata = []
for i in range(1,3):
    df = pd.read_json(f'./data/Google Maps/metadata-sitios/{i}.json',lines=True)
    maps_metadata = pd.concat([maps_metadata,df])
maps_metadata = maps_metadata.reset_index(drop=True)
for i in range(len(maps_metadata)):
    if type(maps_metadata.name[i]) != str:
        lista_metadata.append(i)
maps_metadata.drop(lista_metadata,axis=0,inplace=True)
horarios_maps = maps_metadata[['gmap_id','hours']]
categorias_maps = maps_metadata[['gmap_id','category']]
servicios_maps = maps_metadata[['gmap_id','MISC']]
relativos_maps = maps_metadata[['gmap_id','relative_results']]
maps_metadata = maps_metadata[['gmap_id','name','address','avg_rating','num_of_reviews','price']]


### Script para encontrar ids únicos y después utilizarlos para filtrar el dataframe de reviews con el fin de obtener los establecimientos del giro que deseamos.

categorias = categorias_maps.category.apply(pd.Series,dtype=str)
cols = categorias.shape[1]
lista_cols =[]
for i in range(1,cols+1):
    lista_cols.append(f'cat_{i}')
categorias.columns = lista_cols
cat = pd.concat([categorias_maps['gmap_id'],categorias],axis=1)
cat = pd.melt(cat, id_vars='gmap_id', value_vars=lista_cols, value_name='Categoria')[['gmap_id','Categoria']].dropna().reset_index(drop=True)
# Filtros para locales de alimentos en general.
restaurant = cat.Categoria.str.contains('restaurant') | cat.Categoria.str.contains('Restaurant')
diner = cat.Categoria.str.contains('Diner') | cat.Categoria.str.contains('diner')
grill = cat.Categoria.str.contains('grill') | cat.Categoria.str.contains('Grill')
eatery = cat.Categoria.str.contains('grill') | cat.Categoria.str.contains('Grill')
pizza = cat.Categoria.str.contains('pizzeria') | cat.Categoria.str.contains('Pizzeria') | cat.Categoria.str.contains('Pizza')
tea = cat.Categoria.str.contains('tea') | cat.Categoria.str.contains('Tea')
coffee = cat.Categoria.str.contains('coffee') | cat.Categoria.str.contains('Coffee')
lunch = cat.Categoria.str.contains('lunch') | cat.Categoria.str.contains('Lunch') | cat.Categoria.str.contains('Brunch')
steak = cat.Categoria.str.contains('steak') | cat.Categoria.str.contains('Steak')
snack = cat.Categoria.str.contains('snack') | cat.Categoria.str.contains('Snack')
others_0 = cat.Categoria.str.contains('breakfast') | cat.Categoria.str.contains('Breakfast') | cat.Categoria.str.contains('fast food') | cat.Categoria.str.contains('Fast food')
others_1 = cat.Categoria.str.contains('dinner') | cat.Categoria.str.contains('Dinner')  | cat.Categoria.str.contains('buffet') | cat.Categoria.str.contains('Buffet') | cat.Categoria.str.contains('cafe') | cat.Categoria.str.contains('Cafe') | cat.Categoria.str.contains('seafood ') | cat.Categoria.str.contains('Seafood ') | cat.Categoria.str.contains('health food') | cat.Categoria.str.contains('Health food') | cat.Categoria.str.contains('ramen') | cat.Categoria.str.contains('Ramen') 
food = cat.Categoria.str.contains('food') | cat.Categoria.str.contains('Food')
# Obteniendo los id's únicos para todos los filtros anteriores.
cat = cat[ restaurant | diner | grill | eatery | pizza | tea | coffee | lunch | steak | snack | others_0 | others_1 | food].reset_index(drop=True)
lista_ids = pd.unique(cat.gmap_id).tolist()
cat[cat.isin({'gmap_id':lista_ids})].gmap_id.tolist()


# Aquí cargamos las reviews.

source_path = './data/Google Maps/estados'
list_state = os.listdir(f'{source_path}')
maps_reviews = pd.DataFrame()
for i in list_state:
    list_ = os.listdir(f'{source_path}/{i}')
    for j in list_:
        df = pd.read_json(f'{source_path}/{i}/{j}',lines=True)
        df['estado'] = i[7:]
        maps_reviews = pd.concat([maps_reviews,df],axis=0)
    break
maps_reviews = maps_reviews[['gmap_id','time','name','estado','rating','text','resp']].reset_index(drop=True)
maps_reviews_clean = maps_reviews[maps_reviews.gmap_id.isin(lista_ids)]


# Script para joinear la tabla de hechos (reviews) con la de dimensiones (metadata). Ya están limpias ambas tablas, considerando solo el giro que queremos abordar.

maps_data = maps_reviews_clean.merge(cat,on='gmap_id',how='left')
maps_data = maps_reviews.merge(maps_metadata, on='gmap_id')
maps_data.columns = ['gmap_id','time','user_name','estado','rating','text','resp','business_name','address','avg_rating','num_of_reviews','price']
maps_data.user_name = maps_data.user_name.astype(str)
maps_data.text = maps_data.text.astype(str)
maps_data.time = maps_data.time.astype(np.int64)
maps_data.gmap_id = maps_data.gmap_id.astype(str)

maps_data['resp_time'] = pd.Series(dtype=np.int64)
maps_data['resp_text'] = pd.Series(dtype=str)
for i in range(len(df)):
    if type(maps_data.resp[i]) == dict:
        maps_data.loc[i,'resp_time'] = maps_data.resp[i]['time']
        maps_data.loc[i,'resp_text'] = maps_data.resp[i]['text']
    else:
        maps_data.loc[i,'resp_time'] = 0
        maps_data.loc[i,'resp_text'] = ''
maps_data.resp_time = maps_data.resp_time.fillna(0).apply(lambda x: int(x))
maps_data.resp_text = maps_data.resp_text.fillna('')
maps_data = maps_data[['gmap_id','time','user_name','estado','rating','text','business_name','address','avg_rating','num_of_reviews','price','resp_time','resp_text']]
maps_data = maps_data[maps_data.duplicated() == False].reset_index(drop=True)

maps_data.head()
